# Singularis (Hackathon) — Regex/Heuristics Pipeline v2

## 1) Зачем это всё

**Цель:** извлекать из PDF **детерминированный граф знаний** с 8 типами узлов и типизированными рёбрами, чтобы получить 80–90% качества LLM-рид-аута при 10–100× меньших времени и стоимости.
**Почему не LLM-only:** дорого, медленно, нестабильно на миллионах статей. Нужен «жёсткий» экстрактор с авто-обучением от реальных сбоев.

---

## 2) Что уже сделано (ключевые улучшения)

**S0 (парсинг):**

* Нормализация переносов/дефисов, аккуратная склейка одиночных `\n` → пробел.
* Подписи к фигурам/таблицам, римские `TABLE I`.

**S1 (regex/heuristics):**

* **Робастный экспандер предложений**: не режет числа `60.0` и переносы, корректно вытягивает фразы с `%`.
* **Чистая нормализация чисел/процентов**: `60.0% of` не превращается в `60.0%of`.
* **Постпроцесс кандидатов**:

  * `merge_fragment_nodes` — склейка соседних фрагментов одного правила.
  * `drop_nested_overlaps` — удаление вложенных дублей.
  * `suppress_overlaps` — «арбитр» перекрытий (выбирает более специфичное правило, затем более длинный текст, затем больший `conf`). Безопасно работает для `prov=dict|list` и `prov_multi`.
* **Разводка правил Dataset vs Result**:

  * `Dataset/own_data` больше **не срабатывает** на *measurements*.
  * Добавлены `Result/percent_worse_improve_pair` и `Result/percent_in_measurements_single` с DOTALL и защитой от переносов/скобок.
  * `single` заблокирован, если рядом видится второй `% of measurements` → исчез дубль.
* **Gaps (S1.5 семена):** сбор «пахнущих» предложений из «тяжёлых» секций по seed-паттернам + метод-лексикону.
* **Линковка (близость)**: Result→Hypothesis, Experiment→Result, Technique/Dataset→Experiment, а также Result/Dataset/Technique→Analysis (чтобы граф не пустел на усечённых наборах типов).

**S2 (нормализация/граф):**

* **8 канонических типов**: `Input Fact, Hypothesis, Experiment, Technique, Result, Dataset, Analysis, Conclusion` + терпим опечатки/варианты (`Hypotesis`, `Method`, `Observation`→нормализуются).
* **Фильтр и ремап рёбер** к **разрешённым парам**; при «левом» типе — мап в `supports/refutes` по полярности.
* **Fallback-«скелет»**: даже без некоторых колонок граф остаётся связным (в т.ч. Technique/Dataset→Analysis).
* **Фиксированные позиции (preset)**: узлы раскладываются **в 8 колонок** в едином порядке; фронт просто рендерит `preset`.

**Фронт (Cytoscape):**

* `loadGraph()` (обновлён): берёт `position` из `graph.json`, режет fan-out, фильтрует по `conf`, защищает контейнер от «бесконечной ширины», стили по типам/рёбрам.

---

## 3) Архитектура (S0→S3)

### S0 — Parsing & Structuring (PDF→JSON)

**Вход:** PDF. **Выход:** `s0.json` с метаданными, секциями (IMRaD+), капшенами, нормализованным текстом.

### S1 — Regex/Rules Extraction (Sections/Captions→Nodes&Proto-Edges)

**Вход:** `s0.json`, `common.yaml`.
**Выход:** `s1_graph.json`, `s1_debug.json`.

* Матч правил с весами секций; `conf = rule_weight × section_weight − hedging_penalty (+ bonuses)`.
* Текст узла — **целое предложение** (робастный экспандер).
* Постпроцесс: склейка, удаление вложений, супресс перекрытий.
* Линковка по близости (оконные эвристики).
* **Gaps**: `samples.gaps_head` + `gap_count`.

### S2 — Semantic Linking & Normalization (S1→Final Graph)

**Вход:** `s1_graph.json`, `s1_debug.json`.
**Выход:** `graph.json` (для фронта), `s2_debug.json`.

* Нормализация типов (терпит опечатки), дедуп по `(type,text)` с аккумулированием provenance.
* Валидация рёбер + мягкий ремап.
* Fallback-ребра для связности.
* Раскладка по колонкам (позиции для `preset`).

### S3 — Cross-Paper Linking (после хакатона)

* Лёгкие эмбеддинги **только на узлах** (MiniLM/e5-small), FAISS-индекс, межстатейные `supports/refutes/extends/repeats`.

---

## 4) Форматы артефактов

Остаются как в спецификации (S0/S1/S2). В `graph.json` у каждой ноды: `type ∈ 8`, `data.col/row`, `position.{x,y}`.

---

## 5) Правила (`common.yaml`)

* **Пороги:** `node=0.40`, `edge=0.55` (тюнингуются).
* **Section weights**: высокие для `Results/Discussion/FigureCaption/TableCaption`.
* **Boosts/Penalties:** `caption`, `capture`, `short_penalty`, `edge_participation`.
* **Hedges**: мягкое штрафование.
* **Elements:** унифицированы под 8 типов; добавлены Result-паттерны на проценты в *measurements*; Dataset-правило очищено от ложных триггеров.
* **Gaps seeds:** seed-регексы + метод-лексикон.
* **Linking**: базовые пары для S1 (S2 валидирует окончательно).

---

## 6) «Самообучение» (S1.5 AutoRule)

* Если `gap_count` велик или покрытие слабое → берём `gaps_head`, жёсткий промпт к LLM, получаем **мягкие regex-паттерны** (с sanity-ограничениями) и добавляем в `rules_learned/*.yaml`.
* На следующем проходе **LLM не нужен** для похожих конструкций.

---

## 7) Отладка и кейсы, которые мы закрыли

* **«60.0% of measurements (…40.0%…)»**: раньше дробилось на `40.\n0%`, попадало в `Dataset`; теперь это **один узел `Result`**, текст целиком, без `%of`.
* **Перекрывающиеся матчи (pair vs single)**: сохраняем только **более специфичное** правило (pair), второй кандидат подавляется.
* **Падение по `prov`**: постпроцессы безопасны при `prov=dict|list` и `prov_multi`.
* **Отсутствие рёбер** на усечённых типах: добавлены fallback-линки в S2, а в S1 — лёгкие связи к `Analysis`.

---

## 8) API и фронт

**API:**

* `POST /parse` → S0 (doc_id)
* `POST /extract?doc_id=` → S0→S1→S2 (RQ)
* `GET /status/{doc_id}` → стадии/тайминги/артефакты
* `GET /preview/{doc_id}/{artifact}` → текстовые предпросмотры
* `GET /graph/{doc_id}` → финальный граф

**Фронт (React + Cytoscape):**

* Левая панель: загрузка, прогресс, предпросмотры.
* Правая: канвас графа **в 8 колонок** (`layout: preset`).
* Параметры по умолчанию: `edgeConfMin=0.62`, `maxFanOut=3`, цветовая схема по типам.

---

## 9) Метрики (что меряем)

* **Время/стоимость** на статью (S0/S1/S2 отдельно).
* **Покрытие**: узлы/рёбра против LLM-эталона.
* **Качество**: точность/полнота по ручной разметке (10–20 статей).
* **Динамика авто-обучения**: доля кейсов, ушедших из LLM-вызовов в детерминированные правила.

---

## 10) Ближайшие шаги

1. **Расширить универсальные Result/Hypothesis-пакеты** (частотные формулы/шаблоны в теоретических статьях: eigen/stability/PCA и т.д.).
2. **Аббревиатуры в S2**: `Long form (SHORT)` → унификация узлов.
3. **Усилить линковку**: окно «2 предложения или 1 абзац» + сигнал «совместное упоминание в фигуре/тексте».
4. **Автопайплайн S1.5**: writeback `rules_learned/*.yaml` + простая модерация (sanity-гейты).
5. **Срез из 20–50 статей**: снять кривые «качество→затраты», показать 10–50× экономию.

---

## 11) Как пользоваться в новом чате

* «Есть S0–S2 как выше; давай под PDF X допишем правила».
* Кидай `s0.json`/`s1_debug.json`/фрагменты текста — верну патчи для `common.yaml` (и, при необходимости, минимальные фиксы в `s1.py`/`s2.py`).
* Готов накатить S3 (межстатейные связи) после стабилизации точности S1/S2.

---

**Итог:** у нас теперь **стабильный, дешёвый, расширяемый** экстрактор с 8 каноническими типами, фиксированной визуализацией в колонках и «самообучением» через `gaps`. Он уже закрывает реальные боли (как с *measurements*) и готов к масштабированию на корпус статей с малой долей LLM-фолбэков.
